{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66eed6f4-7006-4fb2-ba3f-3508d7f10938",
   "metadata": {},
   "source": [
    "The main diffrence between Euclidean Distance Metric and Manhattan Distance Metric lies in their calculation method.Eucledian distance measures the straight -line distance between two point in space ,while Manhattan distance measure the distance between two points along the axes at right angle.This diffrence can effect the perfomance of a KNN classfier or regression depending on the data distribution and dimensionally Eucledian distance works well when \n",
    "the dega however it tends to perform poorly when dealiing with high-dimensional data or data with outliers.on the other hand ,Manhattan distance can be robudstt in high dimensional space and with datasets contaning outliers as it is less senstive to various along indvidual dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8624c0-7b92-44c8-b6ee-4a02c9a4e4f1",
   "metadata": {},
   "source": [
    "Choosing the optimal value of k for a KNN classfier or regression involves finding a balance between bias and varaiance .A small value of K can lead to higher varaince and overfitting ,while a large value of K can lead to high bias and underfitting.One common technique to determine the optimal to determine the and testsed on the remaning subset and this process is repested k time each time with diffrent subset held out for testing the average performance across all fold is then calculated for each value of k and the value of k that yield the best performance across all fold is then yield best performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e5853-0872-4c7d-9b06-772520932368",
   "metadata": {},
   "source": [
    "The choice of distance metric in KNN can signficantly impact its perormance some coomon distance metric include.Euclidean distance Mahattan distance and cosine similarty:\n",
    "* Euclidean distance works well when the feature have similar scales and relationship between them as linear\n",
    "* Mahattan distance is more robust to outliers and works when the feature have diffrent scales \n",
    "* Cosine similarity is suitable for high-dimensional data when the direction when important than their magnitiude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a2c4c-81ff-496b-80ac-692c1d2891f7",
   "metadata": {},
   "source": [
    "Some common hyperparmeters in KNN classfier and regression are:\n",
    "1. Number of neighbour: it determines how many nearest neighibour to consider when making predction.Larger while smaller values can lead to more complex boundaries but may increase variance\n",
    "2. Distance metric:This specfies the distance measured used to calculate the similarity between data points.Common choice include Euclideian distance Mahattan distance and cosine similar.\n",
    "3. Weight\n",
    "4. Alogrthim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277fde55-ce74-4193-90ee-89adadf2b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "The size of the traning set can signficantly affect the performance of a KNN classfier or regresssion model\n",
    "1. Small traning set\n",
    "2. Large traning set\n",
    "To optmize "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
